#!/usr/bin/env python3
"""
Airbyte Integration for Sophia Intel Platform
Real data pipeline setup with PostgreSQL, Redis, and Qdrant destinations.
"""
import os
import json
import asyncio
from datetime import datetime
from airbyte_client import AirbyteClient

class SophiaAirbyteIntegration:
    """Sophia Intel specific Airbyte integration."""
    
    def __init__(self):
        self.client = AirbyteClient()
        self.workspace_id = None
        
    async def setup_sophia_pipeline(self):
        """Set up complete data pipeline for Sophia Intel."""
        print("SOPHIA INTEL AIRBYTE PIPELINE SETUP")
        print("=" * 50)
        
        try:
            # Get workspace
            self.workspace_id = await self.client.get_workspace_id()
            print(f"‚úÖ Workspace ID: {self.workspace_id}")
            
            # Check existing resources
            sources = await self.client.get_sources(self.workspace_id)
            destinations = await self.client.get_destinations(self.workspace_id)
            connections = await self.client.get_connections(self.workspace_id)
            
            print(f"\nüìä Current Resources:")
            print(f"  Sources: {len(sources)}")
            print(f"  Destinations: {len(destinations)}")
            print(f"  Connections: {len(connections)}")
            
            # List existing sources
            if sources:
                print(f"\nüì• Existing Sources:")
                for source in sources:
                    print(f"  - {source['name']} ({source['sourceType']})")
                    print(f"    ID: {source['sourceId']}")
            
            # List existing destinations  
            if destinations:
                print(f"\nüì§ Existing Destinations:")
                for dest in destinations:
                    print(f"  - {dest['name']} ({dest['destinationType']})")
                    print(f"    ID: {dest['destinationId']}")
            
            # List existing connections
            if connections:
                print(f"\nüîó Existing Connections:")
                for conn in connections:
                    print(f"  - {conn['name']}")
                    print(f"    Status: {conn.get('status', 'unknown')}")
                    print(f"    ID: {conn['connectionId']}")
            
            # Suggest next steps for Sophia Intel
            print(f"\nüéØ SOPHIA INTEL PIPELINE RECOMMENDATIONS:")
            print(f"  1. ‚úÖ Gong source already configured (sales data)")
            print(f"  2. üîÑ Add PostgreSQL destination (structured data)")
            print(f"  3. üîÑ Add Redis destination (caching layer)")
            print(f"  4. üîÑ Create connections for data flow")
            print(f"  5. üîÑ Set up sync schedules")
            
            return {
                "status": "success",
                "workspace_id": self.workspace_id,
                "resources": {
                    "sources": len(sources),
                    "destinations": len(destinations),
                    "connections": len(connections)
                },
                "existing_sources": [s['name'] for s in sources],
                "existing_destinations": [d['name'] for d in destinations],
                "recommendations": [
                    "Add PostgreSQL destination for Neon database",
                    "Add Redis destination for caching",
                    "Create Gong ‚Üí PostgreSQL connection",
                    "Set up automated sync schedules"
                ]
            }
            
        except Exception as e:
            print(f"‚ùå Pipeline setup failed: {str(e)}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def create_postgresql_destination(self, database_url: str, name: str = "Sophia-PostgreSQL"):
        """Create PostgreSQL destination for Neon database."""
        try:
            # PostgreSQL destination configuration
            config = {
                "host": database_url.split("@")[1].split("/")[0],
                "port": 5432,
                "database": database_url.split("/")[-1],
                "username": database_url.split("://")[1].split(":")[0],
                "password": database_url.split("://")[1].split(":")[1].split("@")[0],
                "ssl": True,
                "ssl_mode": {"mode": "require"}
            }
            
            # Note: This would require the destination definition ID
            # which we can't get due to API restrictions
            print(f"üì§ PostgreSQL destination config prepared for: {name}")
            print(f"   Host: {config['host']}")
            print(f"   Database: {config['database']}")
            print(f"   ‚ö†Ô∏è  Manual creation required via Airbyte UI")
            
            return config
            
        except Exception as e:
            print(f"‚ùå PostgreSQL destination setup failed: {str(e)}")
            return None
    
    async def trigger_all_syncs(self):
        """Trigger sync for all active connections."""
        try:
            connections = await self.client.get_connections(self.workspace_id)
            
            if not connections:
                print("‚ÑπÔ∏è  No connections to sync")
                return []
            
            sync_results = []
            for conn in connections:
                if conn.get('status') == 'active':
                    print(f"üîÑ Triggering sync for: {conn['name']}")
                    result = await self.client.trigger_sync(conn['connectionId'])
                    sync_results.append({
                        "connection": conn['name'],
                        "job_id": result.get('jobId'),
                        "status": "triggered"
                    })
                else:
                    print(f"‚è∏Ô∏è  Skipping inactive connection: {conn['name']}")
            
            return sync_results
            
        except Exception as e:
            print(f"‚ùå Sync trigger failed: {str(e)}")
            return []

async def main():
    """Main integration test and setup."""
    integration = SophiaAirbyteIntegration()
    
    # Set up pipeline
    result = await integration.setup_sophia_pipeline()
    
    if result["status"] == "success":
        print(f"\n‚úÖ AIRBYTE INTEGRATION SUCCESSFUL")
        print(f"üìã Summary: {json.dumps(result, indent=2)}")
        
        # Test PostgreSQL destination config
        neon_url = os.environ.get("NEON_DATABASE_URL", "postgresql://user:pass@host/db")
        pg_config = await integration.create_postgresql_destination(neon_url)
        
        if pg_config:
            print(f"\nüì§ PostgreSQL destination ready for manual setup")
    else:
        print(f"\n‚ùå Integration failed: {result.get('error')}")

if __name__ == "__main__":
    asyncio.run(main())

